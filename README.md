ü§≤üèΩ
```
- [x] MLP
- [x] Token Embedding

- [x] Batch Normalization
- [x] Layer Normalization

- [x] Logistic Regression - Theory
- [x] Gradient Descent/Autograd - Theory

- [-] Byte Pair Encoding

- [ ] Rotary Positional Encoding

- [ ] Quanitization
- [-] LoRA Finetuning
- [-] QLoRA
- [ ] RL Finetuning

- [x] Attention
- [x] Decoder Transformer (GPT)
- [x] Encoder Transformer (BERT - NER/Sentiment Analysis)
- [-] Full Transformer / Cross Attention

- [x] Convolution / CNN
- [x] ResNet
- [ ] YOLO

- [-] RNN
- [-] GRU  
- [-] LSTM

- [x] VAE
- [ ] GAN
- [ ] Diffusion Model

- [ ] Mamba
- [ ] KV Cache
- [ ] Parallelization

- [ ] Vision Transformer
- [ ] UNet

- [ ] Scaling laws - Theory

- [ ] Profiling

- [ ] *karpathy/llama.c
- [ ] *[black-forest-labs/flux](https://github.com/black-forest-labs/flux)
```
