{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f11687d8-5a96-47e8-9a98-d22250136928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\n",
      "18\n",
      "{'\\n': 0, ' ': 1, \"'\": 2, ',': 3, '-': 4, '/': 5, '1': 6, ':': 7, 'A': 8, 'B': 9, 'C': 10, 'D': 11, 'E': 12, 'F': 13, 'G': 14, 'H': 15, 'I': 16, 'J': 17, 'K': 18, 'L': 19, 'M': 20, 'N': 21, 'O': 22, 'P': 23, 'Q': 24, 'R': 25, 'S': 26, 'T': 27, 'U': 28, 'V': 29, 'W': 30, 'X': 31, 'Y': 32, 'Z': 33, 'a': 34, 'b': 35, 'c': 36, 'd': 37, 'e': 38, 'f': 39, 'g': 40, 'h': 41, 'i': 42, 'j': 43, 'k': 44, 'l': 45, 'm': 46, 'n': 47, 'o': 48, 'p': 49, 'q': 50, 'r': 51, 's': 52, 't': 53, 'u': 54, 'v': 55, 'w': 56, 'x': 57, 'y': 58, 'z': 59, '\\xa0': 60, 'Á': 61, 'É': 62, 'ß': 63, 'à': 64, 'á': 65, 'ã': 66, 'ä': 67, 'ç': 68, 'è': 69, 'é': 70, 'ê': 71, 'ì': 72, 'í': 73, 'ñ': 74, 'ò': 75, 'ó': 76, 'õ': 77, 'ö': 78, 'ù': 79, 'ú': 80, 'ü': 81, 'ą': 82, 'ł': 83, 'ń': 84, 'Ś': 85, 'Ż': 86, 'ż': 87} 88 57\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "print(all_letters)\n",
    "data_path = '../../data/names/*.txt'\n",
    "\n",
    "vocabs = \"\"\n",
    "categories = []\n",
    "lang_lines = {}\n",
    "for filename in glob.glob(data_path):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    categories.append(category)\n",
    "    data = open(filename, encoding='utf-8').read().strip()\n",
    "    vocabs += data\n",
    "    lines = vocabs.split('\\n')\n",
    "    lang_lines[category] = lines\n",
    "\n",
    "n_category = len(categories)\n",
    "print(n_category)\n",
    "    \n",
    "itoa = dict(enumerate(sorted(list(set(vocabs)))))\n",
    "atoi = { i: k for k, i in itoa.items()}\n",
    "\n",
    "def to_char(idxs):\n",
    "    return [itoa[idx] for idx in idxs]\n",
    "\n",
    "def to_index(name):\n",
    "    return [atoi[ch] for ch in name]\n",
    "    \n",
    "n_vocabs = len(itoa)\n",
    "print(atoi, len(itoa), n_letters)\n",
    "\n",
    "category_lines = {}\n",
    "for category, lines in lang_lines.items():\n",
    "    category_lines[category] = [torch.tensor(to_index(line)) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3cd43c9-0af4-48dd-99b5-16ab217556f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 88])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(category_lines['Russian'][0], num_classes=n_vocabs).view(-1, 1, n_vocabs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6b5fbfb8-ef86-4ad1-8be7-dd5d964e0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, targets=None):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        if targets is None:\n",
    "            return (output, hidden), None\n",
    "        loss = F.cross_entropy(output, targets)\n",
    "        return (output, hidden), loss\n",
    "\n",
    "    def _init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_vocabs, n_hidden, n_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d95550f-df73-4c21-8ba4-d79842e594a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 18]) torch.Size([6, 128]) None\n"
     ]
    }
   ],
   "source": [
    "# forward\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "input = torch.zeros(6, 88)\n",
    "input[:, 0] = 1\n",
    "(output, next_hidden), p = rnn(input, hidden)\n",
    "print(output.shape, next_hidden.shape, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f532005-2e63-4e4b-bdb1-f421e7ad279d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Arabic', 14)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_label(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    label_i = top_i[0].item()\n",
    "    return categories[label_i], label_i\n",
    "\n",
    "fetch_label(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
